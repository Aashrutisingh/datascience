{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5: Song Classification, Part 2\n",
    "\n",
    "Welcome to Lab 5! We'll pick off where we left off and continue to build a song classifer using k-nearest neighbors. \n",
    "\n",
    "Please complete lab 4 before starting lab 5.\n",
    "\n",
    "Lab 4 is part 1 of the investigation. Lab 5 is part 2 of the investigation.\n",
    "\n",
    "You will build a classifier that guesses whether a song is hip-hop or country, using only the number of times that each word appears in a song's lyrics.  By the end of the project, you should know how to:\n",
    "\n",
    "1. Clean and organize a dataset used to test a machine learning model\n",
    "2. Build a k-nearest neighbors classifier\n",
    "3. Test a classifier on data\n",
    "\n",
    "**Advice.** Develop your answers incrementally. To perform a complicated table manipulation, break it up into steps, perform each step on a different line, give a new name to each result, and check that each intermediate result is what you expect. You can add any additional names or functions you want to the provided cells. \n",
    "\n",
    "To get started, load `datascience`, `numpy`, `plots`, and `gofer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/datascience/tables.py:17: MatplotlibDeprecationWarning: The 'warn' parameter of use() is deprecated since Matplotlib 3.1 and will be removed in 3.3.  If any parameter follows 'warn', they should be pass as keyword, not positionally.\n",
      "  matplotlib.use('agg', warn=False)\n",
      "/usr/local/lib/python3.7/site-packages/datascience/util.py:10: MatplotlibDeprecationWarning: The 'warn' parameter of use() is deprecated since Matplotlib 3.1 and will be removed in 3.3.  If any parameter follows 'warn', they should be pass as keyword, not positionally.\n",
      "  matplotlib.use('agg', warn=False)\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:8: MatplotlibDeprecationWarning: The 'warn' parameter of use() is deprecated since Matplotlib 3.1 and will be removed in 3.3.  If any parameter follows 'warn', they should be pass as keyword, not positionally.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Run this cell to set up the notebook, but please don't change it.\n",
    "import numpy as np\n",
    "import math\n",
    "from datascience import *\n",
    "\n",
    "# These lines set up the plotting functionality and formatting.\n",
    "import matplotlib\n",
    "matplotlib.use('Agg', warn=False)\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plots\n",
    "plots.style.use('fivethirtyeight')\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "warnings.simplefilter('ignore', UserWarning)\n",
    "\n",
    "# These lines load the tests.\n",
    "# from gofer.ok import check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.15.4'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datascience\n",
    "datascience.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview: Recap\n",
    "\n",
    "In lab 4, we completed the following tasks:\n",
    "1. In section 1, we explored the dataset and split the dataset into training data and test data.\n",
    "2. In section 2, we ran through a guided example of the k-Nearest Neightbors (k-NN) classification algorithm.\n",
    "\n",
    "**If you do not remember lab 4, we highly recommend you go back and review it now. It will help you for this lab. **\n",
    "\n",
    "In lab 5, we are going to complete the following tasks:\n",
    "1. Identify some features.\n",
    "2. Define a classifier function using your features and the training set.\n",
    "3. Evaluate its performance (the proportion of correct classifications) on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to set up the lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics = Table.read_table('lyrics.csv')\n",
    "\n",
    "training_proportion = 11/16\n",
    "\n",
    "num_songs = lyrics.num_rows\n",
    "num_train = int(num_songs * training_proportion)\n",
    "num_valid = num_songs - num_train\n",
    "\n",
    "train_lyrics = lyrics.take(np.arange(num_train))\n",
    "test_lyrics = lyrics.take(np.arange(num_train, num_songs))\n",
    "\n",
    "def most_common(label, table):\n",
    "    return table.group(label).sort('count', descending=True).column(label).item(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we're going to extend our classifier from lab 4 to consider more than two features at a time.\n",
    "\n",
    "Euclidean distance still makes sense with more than two features. For `n` different features, we compute the difference between corresponding feature values for two songs, square each of the `n`  differences, sum up the resulting numbers, and take the square root of the sum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Question 1.1 ** <br/>\n",
    "Write a function to compute the Euclidean distance between two **arrays** of features of *arbitrary* (but equal) length.  Use it to compute the distance between the first song in the training set and the first song in the test set, *using all of the features*.  (Remember that the title, artist, and genre of the songs are not features.)\n",
    "\n",
    "**Note:** To convert row objects to arrays, use `np.array`. For example, if `t` was a table, `np.array(t.row(0))` converts row 0 of `t` into an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1482277008140451"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def distance(features1, features2):\n",
    "    \"\"\"The Euclidean distance between two arrays of feature values.\"\"\"\n",
    "    return np.sqrt(np.sum((features1 - features2)**2))\n",
    "\n",
    "distance_first_to_first = distance(np.array(train_lyrics.row(0)[3:]), np.array(test_lyrics.row(0)[3:]))\n",
    "distance_first_to_first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'check' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-684b2e2a3c35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tests/q1_1.py\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'check' is not defined"
     ]
    }
   ],
   "source": [
    "check(\"tests/q1_1.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Creating your own feature set\n",
    "\n",
    "Unfortunately, using all of the features has some downsides.  One clear downside is *computational* -- computing Euclidean distances just takes a long time when we have lots of features.  You might have noticed that in the last question!\n",
    "\n",
    "So we're going to select just 20.  We'd like to choose features that are very *discriminative*. That is, features which lead us to correctly classify as much of the test set as possible.  This process of choosing features that will make a classifier work well is sometimes called *feature selection*, or more broadly *feature engineering*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Question 1.1.1 ** <br/>\n",
    "Look through the list of features (the labels of the `lyrics` table after the first three).  Choose 20 common words that you think might let you distinguish between country and hip-hop songs. Make sure to choose words that are frequent enough that every song contains at least one of them. Don't just choose the 20 most frequent, though... you can do much better.\n",
    "\n",
    "You might want to come back to this question later to improve your list, once you've seen how to evaluate your classifier.  The first time you answer this question, spend some time looking through the features, but not more than 15 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set my_20_features to an array of 20 features (strings that are column labels)\n",
    "\n",
    "my_20_features = np.array(['die', 'love', 'time', 'never', 'live', 'heart', 'night', 'gonna', 'man', 'onli', 'girl', 'wanna', 'alon', 'cri', 'yo', 'sin', 'kill', 'blood', 'heaven', 'gun'])\n",
    "\n",
    "train_20 = train_lyrics.select(my_20_features)\n",
    "test_20 = test_lyrics.select(my_20_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set my_20_features to an array of 20 features (strings that are column labels)\n",
    "\n",
    "my_20_features_1 = make_array('die', 'love', 'time', 'never', 'live', 'heart', 'night', 'gonna', 'man', 'onli', 'girl', 'wanna', 'alon', 'cri', 'yo', 'sin', 'kill', 'blood', 'heaven', 'gun')\n",
    "\n",
    "train_20 = train_lyrics.select(my_20_features)\n",
    "test_20 = test_lyrics.select(my_20_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set my_20_features to an array of 20 features (strings that are column labels)\n",
    "\n",
    "my_20_features_2 = ['die', 'love', 'time', 'never', 'live', 'heart', 'night', 'gonna', 'man', 'onli', 'girl', 'wanna', 'alon', 'cri', 'yo', 'sin', 'kill', 'blood', 'heaven', 'gun']\n",
    "\n",
    "train_20 = train_lyrics.select(my_20_features)\n",
    "test_20 = test_lyrics.select(my_20_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This test makes sure that you have chosen words such that at least one appears in each song. If you can't find words that satisfy this test just through intuition, try writing code to print out the titles of songs that do not contain any words from your list, then look at the words they do contain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_f' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-b0f0fc42e67f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_f' is not defined"
     ]
    }
   ],
   "source": [
    "train_f.row(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "tuple.index(x): x not in tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-580a222a7409>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/datascience/tables.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, column_label)\u001b[0m\n\u001b[1;32m   2883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2884\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2885\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2887\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_or_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/datascience/tables.py\u001b[0m in \u001b[0;36mcolumn_index\u001b[0;34m(self, label)\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcolumn_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;34m\"\"\"Return the index of a column by looking up its label.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mcolumn_or_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: tuple.index(x): x not in tuple"
     ]
    }
   ],
   "source": [
    "np.array(train_f.row(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "tuple.index(x): x not in tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-4e518509526b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/datascience/tables.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, column_label)\u001b[0m\n\u001b[1;32m   2883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2884\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2885\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2887\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_or_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/datascience/tables.py\u001b[0m in \u001b[0;36mcolumn_index\u001b[0;34m(self, label)\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcolumn_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;34m\"\"\"Return the index of a column by looking up its label.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mcolumn_or_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: tuple.index(x): x not in tuple"
     ]
    }
   ],
   "source": [
    "np.sum(np.array(train_f.row(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "tuple.index(x): x not in tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-e16a47d1fe2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#== 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtest_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# train_f.apply(lambda r: np.sum(r) == 0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# train_f.apply(lambda r: np.sum(r) == 0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-e16a47d1fe2a>\u001b[0m in \u001b[0;36mtest_fn\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_lyrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_20_features\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# using np.array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#== 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtest_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# train_f.apply(lambda r: np.sum(r) == 0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2228\u001b[0m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0;32m-> 2229\u001b[0;31m                           initial=initial, where=where)\n\u001b[0m\u001b[1;32m   2230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/datascience/tables.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, column_label)\u001b[0m\n\u001b[1;32m   2883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2884\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2885\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2887\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_or_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/datascience/tables.py\u001b[0m in \u001b[0;36mcolumn_index\u001b[0;34m(self, label)\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcolumn_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;34m\"\"\"Return the index of a column by looking up its label.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mcolumn_or_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: tuple.index(x): x not in tuple"
     ]
    }
   ],
   "source": [
    "train_f = train_lyrics.select(my_20_features) # using np.array\n",
    "def test_fn(row):\n",
    "    return np.sum(row) #== 0\n",
    "test_fn(train_f.row(0))\n",
    "# train_f.apply(lambda r: np.sum(r) == 0)\n",
    "# train_f.apply(lambda r: np.sum(r) == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "train_f = train_lyrics.select(my_20_features_1) # using make_array\n",
    "print(np.count_nonzero(train_f.apply(lambda r: np.sum(np.abs(np.array(r))) == 0)) < 150)\n",
    "print(np.count_nonzero(train_f.apply(lambda r: np.sum(np.abs(make_array(r))) == 0)) < 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "train_f = train_lyrics.select(my_20_features_2) # using Python list\n",
    "print(np.count_nonzero(train_f.apply(lambda r: np.sum(np.abs(np.array(r))) == 0)) < 150)\n",
    "print(np.count_nonzero(train_f.apply(lambda r: np.sum(np.abs(make_array(r))) == 0)) < 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>die</th> <th>love</th> <th>time</th> <th>never</th> <th>live</th> <th>heart</th> <th>night</th> <th>gonna</th> <th>man</th> <th>onli</th> <th>girl</th> <th>wanna</th> <th>alon</th> <th>cri</th> <th>yo</th> <th>sin</th> <th>kill</th> <th>blood</th> <th>heaven</th> <th>gun</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>0         </td> <td>0.00154799</td> <td>0.00464396</td> <td>0.00154799</td> <td>0.00154799</td> <td>0         </td> <td>0         </td> <td>0         </td> <td>0.00154799</td> <td>0.00154799</td> <td>0         </td> <td>0.00464396</td> <td>0         </td> <td>0        </td> <td>0.00309597</td> <td>0       </td> <td>0         </td> <td>0         </td> <td>0.00154799</td> <td>0         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0.00236407</td> <td>0         </td> <td>0.0260047 </td> <td>0.00236407</td> <td>0         </td> <td>0         </td> <td>0         </td> <td>0.00236407</td> <td>0.00236407</td> <td>0         </td> <td>0.00236407</td> <td>0         </td> <td>0         </td> <td>0        </td> <td>0         </td> <td>0       </td> <td>0.00236407</td> <td>0.00236407</td> <td>0         </td> <td>0.00236407</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0.00177305</td> <td>0         </td> <td>0.00177305</td> <td>0.00177305</td> <td>0.0106383 </td> <td>0         </td> <td>0         </td> <td>0         </td> <td>0.0035461 </td> <td>0         </td> <td>0         </td> <td>0         </td> <td>0         </td> <td>0        </td> <td>0.00177305</td> <td>0       </td> <td>0         </td> <td>0         </td> <td>0         </td> <td>0.00177305</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0         </td> <td>0         </td> <td>0.0175439 </td> <td>0         </td> <td>0         </td> <td>0.00438597</td> <td>0.00438597</td> <td>0         </td> <td>0         </td> <td>0.0307017 </td> <td>0         </td> <td>0         </td> <td>0         </td> <td>0.0175439</td> <td>0         </td> <td>0       </td> <td>0         </td> <td>0         </td> <td>0         </td> <td>0         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0         </td> <td>0.0146342 </td> <td>0         </td> <td>0.00487805</td> <td>0         </td> <td>0.00487805</td> <td>0         </td> <td>0         </td> <td>0         </td> <td>0         </td> <td>0         </td> <td>0         </td> <td>0         </td> <td>0        </td> <td>0         </td> <td>0       </td> <td>0         </td> <td>0         </td> <td>0         </td> <td>0         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0         </td> <td>0.00833333</td> <td>0.00833333</td> <td>0         </td> <td>0         </td> <td>0.00416667</td> <td>0         </td> <td>0.00416667</td> <td>0.00416667</td> <td>0         </td> <td>0         </td> <td>0         </td> <td>0.00416667</td> <td>0        </td> <td>0         </td> <td>0       </td> <td>0         </td> <td>0         </td> <td>0         </td> <td>0         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0         </td> <td>0         </td> <td>0         </td> <td>0         </td> <td>0         </td> <td>0         </td> <td>0         </td> <td>0.00641026</td> <td>0         </td> <td>0         </td> <td>0         </td> <td>0         </td> <td>0         </td> <td>0        </td> <td>0         </td> <td>0       </td> <td>0         </td> <td>0         </td> <td>0         </td> <td>0         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0         </td> <td>0         </td> <td>0.00479616</td> <td>0.00959233</td> <td>0         </td> <td>0         </td> <td>0         </td> <td>0         </td> <td>0         </td> <td>0         </td> <td>0         </td> <td>0         </td> <td>0         </td> <td>0        </td> <td>0.00239808</td> <td>0       </td> <td>0         </td> <td>0         </td> <td>0         </td> <td>0.00239808</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0         </td> <td>0.0274725 </td> <td>0         </td> <td>0.00549451</td> <td>0         </td> <td>0.00549451</td> <td>0.010989  </td> <td>0         </td> <td>0         </td> <td>0         </td> <td>0         </td> <td>0         </td> <td>0.010989  </td> <td>0        </td> <td>0         </td> <td>0       </td> <td>0         </td> <td>0         </td> <td>0         </td> <td>0         </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>0         </td> <td>0         </td> <td>0         </td> <td>0         </td> <td>0         </td> <td>0         </td> <td>0         </td> <td>0         </td> <td>0         </td> <td>0         </td> <td>0         </td> <td>0         </td> <td>0         </td> <td>0        </td> <td>0.014218  </td> <td>0.014218</td> <td>0         </td> <td>0         </td> <td>0         </td> <td>0         </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (1173 rows omitted)</p>"
      ],
      "text/plain": [
       "die        | love       | time       | never      | live       | heart      | night      | gonna      | man        | onli       | girl       | wanna      | alon       | cri       | yo         | sin      | kill       | blood      | heaven     | gun\n",
       "0          | 0.00154799 | 0.00464396 | 0.00154799 | 0.00154799 | 0          | 0          | 0          | 0.00154799 | 0.00154799 | 0          | 0.00464396 | 0          | 0         | 0.00309597 | 0        | 0          | 0          | 0.00154799 | 0\n",
       "0.00236407 | 0          | 0.0260047  | 0.00236407 | 0          | 0          | 0          | 0.00236407 | 0.00236407 | 0          | 0.00236407 | 0          | 0          | 0         | 0          | 0        | 0.00236407 | 0.00236407 | 0          | 0.00236407\n",
       "0.00177305 | 0          | 0.00177305 | 0.00177305 | 0.0106383  | 0          | 0          | 0          | 0.0035461  | 0          | 0          | 0          | 0          | 0         | 0.00177305 | 0        | 0          | 0          | 0          | 0.00177305\n",
       "0          | 0          | 0.0175439  | 0          | 0          | 0.00438597 | 0.00438597 | 0          | 0          | 0.0307017  | 0          | 0          | 0          | 0.0175439 | 0          | 0        | 0          | 0          | 0          | 0\n",
       "0          | 0.0146342  | 0          | 0.00487805 | 0          | 0.00487805 | 0          | 0          | 0          | 0          | 0          | 0          | 0          | 0         | 0          | 0        | 0          | 0          | 0          | 0\n",
       "0          | 0.00833333 | 0.00833333 | 0          | 0          | 0.00416667 | 0          | 0.00416667 | 0.00416667 | 0          | 0          | 0          | 0.00416667 | 0         | 0          | 0        | 0          | 0          | 0          | 0\n",
       "0          | 0          | 0          | 0          | 0          | 0          | 0          | 0.00641026 | 0          | 0          | 0          | 0          | 0          | 0         | 0          | 0        | 0          | 0          | 0          | 0\n",
       "0          | 0          | 0.00479616 | 0.00959233 | 0          | 0          | 0          | 0          | 0          | 0          | 0          | 0          | 0          | 0         | 0.00239808 | 0        | 0          | 0          | 0          | 0.00239808\n",
       "0          | 0.0274725  | 0          | 0.00549451 | 0          | 0.00549451 | 0.010989   | 0          | 0          | 0          | 0          | 0          | 0.010989   | 0         | 0          | 0        | 0          | 0          | 0          | 0\n",
       "0          | 0          | 0          | 0          | 0          | 0          | 0          | 0          | 0          | 0          | 0          | 0          | 0          | 0         | 0.014218   | 0.014218 | 0          | 0          | 0          | 0\n",
       "... (1173 rows omitted)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.00154799, 0.00464396, ..., 0.        , 0.00154799,\n",
       "        0.        ],\n",
       "       [0.00236407, 0.        , 0.02600473, ..., 0.00236407, 0.        ,\n",
       "        0.00236407],\n",
       "       [0.00177305, 0.        , 0.00177305, ..., 0.        , 0.        ,\n",
       "        0.00177305],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.00769231, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.00851064, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.00584795, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_f.apply(lambda r: r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        , 0.00154799, 0.00464396, ..., 0.        ,\n",
       "         0.00154799, 0.        ]],\n",
       "\n",
       "       [[0.00236407, 0.        , 0.02600473, ..., 0.00236407,\n",
       "         0.        , 0.00236407]],\n",
       "\n",
       "       [[0.00177305, 0.        , 0.00177305, ..., 0.        ,\n",
       "         0.        , 0.00177305]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.        , 0.        , 0.00769231, ..., 0.        ,\n",
       "         0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.00851064, ..., 0.        ,\n",
       "         0.        , 0.        ]],\n",
       "\n",
       "       [[0.00584795, 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_f.apply(lambda r: make_array(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.00154799, 0.00464396, ..., 0.        , 0.00154799,\n",
       "        0.        ],\n",
       "       [0.00236407, 0.        , 0.02600473, ..., 0.00236407, 0.        ,\n",
       "        0.00236407],\n",
       "       [0.00177305, 0.        , 0.00177305, ..., 0.        , 0.        ,\n",
       "        0.00177305],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.00769231, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.00851064, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.00584795, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_f.apply(lambda r: np.array(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.6.9\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: datascience\n",
      "Version: 0.15.1\n",
      "Summary: A Jupyter notebook Python library for introductory data science\n",
      "Home-page: https://github.com/data-8/datascience\n",
      "Author: John DeNero, David Culler, Alvin Wan, Sam Lau\n",
      "Author-email: ds8-instructors@berkeley.edu\n",
      "License: UNKNOWN\n",
      "Location: /srv/app/venv/lib/python3.6/site-packages\n",
      "Requires: scipy, coveralls, setuptools, sphinx, folium, matplotlib, bokeh, coverage, pytest, pandas, ipython, numpy\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 20.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip show datascience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: numpy\n",
      "Version: 1.16.0\n",
      "Summary: NumPy is the fundamental package for array computing with Python.\n",
      "Home-page: https://www.numpy.org\n",
      "Author: Travis E. Oliphant et al.\n",
      "Author-email: None\n",
      "License: BSD\n",
      "Location: /srv/app/venv/lib/python3.6/site-packages\n",
      "Requires: \n",
      "\u001b[33mYou are using pip version 9.0.3, however version 20.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip show numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "<gofer.ok.OKTestsResult at 0x102c93e48>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check(\"tests/q1_1_1.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's classify the first song from our test set using these features.  You can examine the song by running the cells below. Do you think it will be classified correctly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Song:\")\n",
    "test_lyrics.take(0).select('Title', 'Artist', 'Genre').show()\n",
    "print(\"Features:\")\n",
    "test_20.take(0).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we want to look for the songs in the training set that are most alike our test song.  We will calculate the Euclidean distances from the test song (using the 20 selected features) to all songs in the training set.  You could do this with a `for` loop, but to make it computationally faster, we have provided a function, `fast_distances`, to do this for you.  Read its documentation to make sure you understand what it does.  (You don't need to read the code in its body unless you want to.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell to define fast_distances.\n",
    "\n",
    "def fast_distances(test_row, train_rows):\n",
    "    \"\"\"An array of the distances between test_row and each row in train_rows.\n",
    "\n",
    "    Takes 2 arguments:\n",
    "      test_row: A row of a table containing features of one\n",
    "        test song (e.g., test_20.row(0)).\n",
    "      train_rows: A table of features (for example, the whole\n",
    "        table train_20).\"\"\"\n",
    "    assert train_rows.num_columns < 50, \"Make sure you're not using all the features of the lyrics table.\"\n",
    "    counts_matrix = np.asmatrix(train_rows.columns).transpose()\n",
    "    diff = np.tile(np.array(test_row), [counts_matrix.shape[0], 1]) - counts_matrix\n",
    "    distances = np.squeeze(np.asarray(np.sqrt(np.square(diff).sum(1))))\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Question 1.1.2 ** <br/>\n",
    "Use the `fast_distances` function provided above to compute the distance from the first song in the test set to all the songs in the training set, **using your set of 20 features**.  Make a new table called `genre_and_distances` with one row for each song in the training set and two columns:\n",
    "* The `\"Genre\"` of the training song\n",
    "* The `\"Distance\"` from the first song in the test set \n",
    "\n",
    "Ensure that `genre_and_distances` is **sorted in increasing order by distance to the first test song**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "for_assignment_type": "student"
   },
   "outputs": [],
   "source": [
    "# The staff solution took 4 lines of code.\n",
    "genre_and_distances = ...\n",
    "genre_and_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check(\"tests/q1_1_2.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Question 1.1.3 ** <br/>\n",
    "Now compute the 5-nearest neighbors classification of the first song in the test set.  That is, decide on its genre by finding the most common genre among its 5 nearest neighbors, according to the distances you've calculated.  Then check whether your classifier chose the right genre.  (Depending on the features you chose, your classifier might not get this song right, and that's okay.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set my_assigned_genre to the most common genre among these.\n",
    "my_assigned_genre = ...\n",
    "\n",
    "# Set my_assigned_genre_was_correct to True if my_assigned_genre\n",
    "# matches the actual genre of the first song in the test set.\n",
    "my_assigned_genre_was_correct = ...\n",
    "\n",
    "print(\"The assigned genre, {}, was{}correct.\".format(my_assigned_genre, \" \" if my_assigned_genre_was_correct else \" not \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check(\"tests/q1_1_3.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. A classifier function\n",
    "\n",
    "Now we can write a single function that encapsulates the whole process of classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Question 1.2.1 ** <br/>\n",
    "Write a function called `classify`.  It should take the following four arguments:\n",
    "* A row of features for a song to classify (e.g., `test_20.row(0)`).\n",
    "* A table with a column for each feature (e.g., `train_20`).\n",
    "* An array of classes that has as many items as the previous table has rows, and in the same order.\n",
    "* `k`, the number of neighbors to use in classification.\n",
    "\n",
    "It should return the class a `k`-nearest neighbor classifier picks for the given row of features (the string `'Country'` or the string `'Hip-hop'`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(test_row, train_rows, train_classes, k):\n",
    "    \"\"\"Return the most common class among k nearest neigbors to test_row.\"\"\"\n",
    "    distances = fast_distances(test_row, train_rows)\n",
    "    genre_and_distances = ...\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check(\"tests/q1_2_1.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Question 1.2.2 ** <br/>\n",
    "Assign `grandpa_genre` to the genre predicted by your classifier for the song \"Grandpa Got Runned Over By A John Deere\" in the test set, using **9 neighbors** and using your 20 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The staff solution first defined a row object called grandpa_features.\n",
    "grandpa_features = ...\n",
    "grandpa_genre = ...\n",
    "grandpa_genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check(\"tests/q1_2_2.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, when we evaluate our classifier, it will be useful to have a classification function that is specialized to use a fixed training set and a fixed value of `k`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Question 1.2.3 ** <br/>\n",
    "Create a classification function that takes as its argument a row containing your 20 features and classifies that row using the 5-nearest neighbors algorithm with `train_20` as its training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_one_argument(row):\n",
    "    ...\n",
    "\n",
    "# When you're done, this should produce 'Hip-hop' or 'Country'.\n",
    "classify_one_argument(test_20.row(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check(\"tests/q1_2_3.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Evaluating your classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that it's easy to use the classifier, let's see how accurate it is on the whole test set.\n",
    "\n",
    "**Question 1.3.1.** Use `classify_one_argument` and `apply` to classify every song in the test set.  Name these guesses `test_guesses`.  **Then**, compute the proportion of correct classifications. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_guesses = ...\n",
    "proportion_correct = ...\n",
    "proportion_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check(\"tests/q1_3_1.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, you've gone through one cycle of classifier design.  Let's summarize the steps:\n",
    "1. From available data, select test and training sets.\n",
    "2. Choose an algorithm you're going to use for classification.\n",
    "3. Identify some features.\n",
    "4. Define a classifier function using your features and the training set.\n",
    "5. Evaluate its performance (the proportion of correct classifications) on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You're finished with lab 5 and Data 8.3x! You've created your own song classifer using k-nearest neighbors. \n",
    "\n",
    "**If you want to continue, you can read about classification online and try to build an even more accurate classifier.**\n",
    "\n",
    "In order to successfully submit your assignment, follow these steps...\n",
    "- **IMPORTANT** Before you do anything, **Save and Checkpoint** from the `File` menu. Please do this first before running the cell below,\n",
    "- **run all the tests and verify that they all pass** (the next cell has a shortcut for that), \n",
    "- **Review the notebook one last time** If you make any changes, please **Save and Checkpoint** again.\n",
    "- **Hit the Submit button** Your submission will be saved and grade will be posted when it's finished running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# For your convenience, you can run this cell to run all the tests at once!\n",
    "import glob\n",
    "from gofer.ok import grade_notebook\n",
    "if not globals().get('__GOFER_GRADER__', False):\n",
    "    display(grade_notebook('lab05.ipynb', sorted(glob.glob('tests/q*.py'))))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "course": "8x",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "lab": "lab05",
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "section": "3"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
